---
title: "Task3"
author: "Sara Regina Ferreira de Faria"
date: "27/09/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## How can you efficiently store an n-gram model (think Markov Chains)?



## How can you use the knowledge about word frequencies to make your model smaller and more efficient?



## How many parameters do you need (i.e. how big is n in your n-gram model)?



## Can you think of simple ways to "smooth" the probabilities (think about giving all n-grams a non-zero probability even if they aren't observed in the data) ?



## How do you evaluate whether your model is any good?



## How can you use backoff models to estimate the probability of unobserved n-grams?



